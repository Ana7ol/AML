{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.2.2)\n",
      "Collecting kagglehub\n",
      "  Using cached kagglehub-0.3.12-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (1.5.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.3.1)\n",
      "Collecting lightly\n",
      "  Using cached lightly-1.5.20-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from kagglehub) (23.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from kagglehub) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from kagglehub) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from kagglehub) (4.66.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.11/site-packages (from torch) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.11/site-packages (from lightly) (2023.11.17)\n",
      "Collecting hydra-core>=1.0.0 (from lightly)\n",
      "  Using cached hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting lightly_utils~=0.0.0 (from lightly)\n",
      "  Using cached lightly_utils-0.0.2-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.11/site-packages (from lightly) (1.16.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (from lightly) (0.18.1)\n",
      "Requirement already satisfied: pydantic>=1.10.5 in /opt/conda/lib/python3.11/site-packages (from lightly) (2.8.2)\n",
      "Collecting pytorch_lightning>=1.0.4 (from lightly)\n",
      "  Using cached pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: urllib3>=1.25.3 in /opt/conda/lib/python3.11/site-packages (from lightly) (2.1.0)\n",
      "Collecting aenum>=3.1.11 (from lightly)\n",
      "  Using cached aenum-3.1.16-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting omegaconf<2.4,>=2.2 (from hydra-core>=1.0.0->lightly)\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.0.0->lightly)\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic>=1.10.5->lightly) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.11/site-packages (from pydantic>=1.10.5->lightly) (2.20.1)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch_lightning>=1.0.4->lightly)\n",
      "  Using cached torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning>=1.0.4->lightly)\n",
      "  Using cached lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->kagglehub) (3.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.4)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (3.11.13)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from lightning-utilities>=0.10.0->pytorch_lightning>=1.0.4->lightly) (69.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.18.3)\n",
      "Using cached kagglehub-0.3.12-py3-none-any.whl (67 kB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached lightly-1.5.20-py3-none-any.whl (851 kB)\n",
      "Using cached aenum-3.1.16-py3-none-any.whl (165 kB)\n",
      "Using cached hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "Using cached lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\n",
      "Using cached pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
      "Using cached lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Using cached torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
      "Installing collected packages: antlr4-python3-runtime, aenum, omegaconf, lightning-utilities, lightly_utils, kagglehub, hydra-core, seaborn, torchmetrics, pytorch_lightning, lightly\n",
      "Successfully installed aenum-3.1.16 antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 kagglehub-0.3.12 lightly-1.5.20 lightly_utils-0.0.2 lightning-utilities-0.14.3 omegaconf-2.3.0 pytorch_lightning-2.5.1.post0 seaborn-0.13.2 torchmetrics-1.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas kagglehub seaborn matplotlib scikit-learn torch lightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, precision_recall_fscore_support\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from lightly.loss import NTXentLoss\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import os # For file path joining\n",
    "import kagglehub\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/jovyan/.cache/kagglehub/datasets/ellipticco/elliptic-data-set/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "PATH = kagglehub.dataset_download(\"ellipticco/elliptic-data-set\")\n",
    "print(\"Path to dataset files:\", PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES = 166  # Time step + 165 features\n",
    "EMBEDDING_DIM = 256\n",
    "ENCODER_EMBEDDING_DIM = 256\n",
    "PROJECTION_DIM = 64\n",
    "BATCH_SIZE = 256 \n",
    "EPOCHS = 10 \n",
    "LEARNING_RATE = 1e-3 \n",
    "TEMPERATURE = 0.1\n",
    "\n",
    "AUG_NOISE_LEVEL = 0.03\n",
    "AUG_MASK_FRACTION = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Elliptic dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Elliptic dataset...\")\n",
    "try:\n",
    "    classes_df = pd.read_csv(PATH + \"/elliptic_bitcoin_dataset/elliptic_txs_classes.csv\")\n",
    "    features_df = pd.read_csv(PATH + \"/elliptic_bitcoin_dataset/elliptic_txs_features.csv\")\n",
    "    edge_df = pd.read_csv(PATH + \"/elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv\")\n",
    "\n",
    "    # print(classes_df.head(), end=\"\\n\\n\")\n",
    "    # print(features_df.head(), end=\"\\n\\n\")\n",
    "    # print(edge_df.head())\n",
    "except FileNotFoundError:\n",
    "\n",
    "    print(f\"Error: Dataset files not found in {PATH}\")\n",
    "    print(\"Please download the Elliptic dataset and place it in the correct directory,\")\n",
    "    print(\"or update the DATA_DIR variable.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['txId', 'Time step', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8',\n",
      "       ...\n",
      "       'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164',\n",
      "       'f165'],\n",
      "      dtype='object', length=167)\n"
     ]
    }
   ],
   "source": [
    "#Assign feature headers (txId, Time step, f1 to f165)\n",
    "feature_headers = ['txId', 'Time step'] + [f'f{i}' for i in range(1, 166)]\n",
    "features_df.columns = feature_headers\n",
    "print(features_df.columns)\n",
    "\n",
    "df = pd.merge(features_df, classes_df, on='txId', how='left')\n",
    "\n",
    "# Map classes for evaluation: 1 (illicit) -> 1, 2 (licit) -> 0, unknown -> NaN\n",
    "df['class'] = df['class'].map({'1': 1, '2': 0})\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "# Features: Time step + f1 to f165\n",
    "X_cols = ['Time step'] + [f'f{i}' for i in range(1, 166)]\n",
    "X_all = df[X_cols].values\n",
    "y_all = df['class'].values # Contains NaN for unknowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total transactions: 203768\n",
      "Transactions with known labels: 46564\n",
      "Illicit (1): 4545, Licit (0): 42019\n"
     ]
    }
   ],
   "source": [
    "# Identify known labels for evaluation later\n",
    "known_indices = df.index[df['class'].notna()].tolist()\n",
    "y_known = df.loc[known_indices, 'class'].values.astype(int)\n",
    "txId_known = df.loc[known_indices, 'txId'].values # Keep track of txId if needed\n",
    "\n",
    "print(f\"Total transactions: {len(df)}\")\n",
    "print(f\"Transactions with known labels: {len(known_indices)}\")\n",
    "print(f\"Illicit (1): {np.sum(y_known == 1)}, Licit (0): {np.sum(y_known == 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling features...\n"
     ]
    }
   ],
   "source": [
    "# Scale features (fit only on training data, but here we apply to all for unsupervised)\n",
    "print(\"Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_all_scaled = scaler.fit_transform(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EllipticDataset(Dataset):\n",
    "    def __init__(self, features):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return single view for simplified contrastive loss\n",
    "        return self.features[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EllipticDatasetAugmented(Dataset):\n",
    "    def __init__(self, features, noise_level=0.05, mask_fraction=0.15):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.noise_level = noise_level\n",
    "        self.mask_fraction = mask_fraction\n",
    "        self.n_features = features.shape[1]\n",
    "        print(f\"Augmented Dataset Config: Noise Level={self.noise_level}, Mask Fraction={self.mask_fraction}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def _augment(self, x):\n",
    "        # Apply noise\n",
    "        noise = torch.randn_like(x) * self.noise_level\n",
    "        x_noisy = x + noise\n",
    "        # Apply masking\n",
    "        # Create mask on the same device as x for efficiency if x is already on GPU in some contexts\n",
    "        mask = torch.rand(self.n_features, device=x.device) > self.mask_fraction\n",
    "        x_masked = x_noisy * mask\n",
    "        return x_masked\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original_x = self.features[idx]\n",
    "        # Create two different augmentations of the same sample\n",
    "        view1 = self._augment(original_x.clone()) # Use clone to avoid modifying original tensor\n",
    "        view2 = self._augment(original_x.clone())\n",
    "        return view1, view2 # Return two views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Training DataLoader with AUGMENTATION...\n",
      "Augmented Dataset Config: Noise Level=0.03, Mask Fraction=0.15\n",
      "Setting up Evaluation DataLoader WITHOUT augmentation...\n"
     ]
    }
   ],
   "source": [
    "# # Use all data for unsupervised training\n",
    "# dataset = EllipticDataset(X_all_scaled)\n",
    "# # drop_last=True is important for the artificial pairing in contrastive_loss\n",
    "# dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, drop_last=True)\n",
    "\n",
    "print(\"Setting up Training DataLoader with AUGMENTATION...\")\n",
    "train_dataset = EllipticDatasetAugmented(X_all_scaled, noise_level=AUG_NOISE_LEVEL, mask_fraction=AUG_MASK_FRACTION)\n",
    "# Use drop_last=True if your batch size doesn't perfectly divide the dataset size\n",
    "# Increase num_workers if data loading is a bottleneck (start with 2 or 4)\n",
    "dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=2, pin_memory=True if DEVICE=='cuda' else False)\n",
    "\n",
    "# Use the SIMPLE dataset for the evaluation dataloader - KEEP THIS\n",
    "print(\"Setting up Evaluation DataLoader WITHOUT augmentation...\")\n",
    "eval_dataset = EllipticDataset(X_all_scaled)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=BATCH_SIZE * 2, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNGRUEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, cnn_channels1=32, cnn_channels2=64, cnn_channels3=128, cnn_channels4=256,\n",
    "                 kernel_size=9, pool_kernel=2,\n",
    "                 gru_hidden_size=128, gru_layers=4, bidirectional=True,\n",
    "                 embedding_dim=64):\n",
    "        super(CNNGRUEncoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.conv1 = nn.Conv1d(1, cnn_channels1, kernel_size, padding='same')\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(pool_kernel)\n",
    "        self.conv2 = nn.Conv1d(cnn_channels1, cnn_channels2, kernel_size, padding='same')\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(pool_kernel)\n",
    "        self.conv3 = nn.Conv1d(cnn_channels2, cnn_channels3, kernel_size, padding='same')\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool1d(pool_kernel)\n",
    "        self.conv4 = nn.Conv1d(cnn_channels3, cnn_channels4, kernel_size, padding='same')\n",
    "        self.relu4 = nn.ReLU()\n",
    "        # self.pool3 = nn.MaxPool1d(pool_kernel)\n",
    "\n",
    "        l_out1 = math.floor(input_dim / pool_kernel)\n",
    "        l_out2 = math.floor(l_out1 / pool_kernel)\n",
    "        l_out3 = math.floor(l_out2 / pool_kernel)\n",
    "        l_out4 = math.floor(l_out3 / pool_kernel)\n",
    "        self.cnn_output_length = l_out4\n",
    "        self.cnn_output_channels = cnn_channels4\n",
    "\n",
    "        self.gru = nn.GRU(self.cnn_output_channels, gru_hidden_size, gru_layers,\n",
    "                          batch_first=True, bidirectional=bidirectional)\n",
    "        \n",
    "        gru_output_dim = gru_hidden_size * (2 if bidirectional else 1)\n",
    "        self.fc_out = nn.Linear(gru_output_dim, embedding_dim)\n",
    "        print(f\"CNN Output Sequence Length: {self.cnn_output_length}, Channels: {self.cnn_output_channels}\")\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        # x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        # x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        # x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.relu3(self.conv3(x))\n",
    "        x = self.relu4(self.conv4(x))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        _, h_n = self.gru(x)\n",
    "        if self.gru.bidirectional:\n",
    "            gru_out = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n",
    "        else:\n",
    "            gru_out = h_n[-1,:,:]\n",
    "        embedding = self.fc_out(gru_out)\n",
    "        embedding = F.normalize(embedding, p=2, dim=1)\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=ENCODER_EMBEDDING_DIM, hidden_dim=ENCODER_EMBEDDING_DIM, output_dim=PROJECTION_DIM):\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        # Simple 2-layer MLP as projection head\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        print(f\"Projection Head: Input={input_dim}, Hidden={hidden_dim}, Output={output_dim}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        # Note: NTXentLoss often includes normalization internally, or you can add it here\n",
    "        # x = F.normalize(x, p=2, dim=1) # Optional normalization here\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Output Sequence Length: 10, Channels: 256\n",
      "\n",
      "CNN-GRU Encoder Architecture:\n",
      "OptimizedModule(\n",
      "  (_orig_mod): CNNGRUEncoder(\n",
      "    (conv1): Conv1d(1, 32, kernel_size=(9,), stride=(1,), padding=same)\n",
      "    (relu1): ReLU()\n",
      "    (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv1d(32, 64, kernel_size=(9,), stride=(1,), padding=same)\n",
      "    (relu2): ReLU()\n",
      "    (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv3): Conv1d(64, 128, kernel_size=(9,), stride=(1,), padding=same)\n",
      "    (relu3): ReLU()\n",
      "    (pool3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv4): Conv1d(128, 256, kernel_size=(9,), stride=(1,), padding=same)\n",
      "    (relu4): ReLU()\n",
      "    (gru): GRU(256, 128, num_layers=4, batch_first=True, bidirectional=True)\n",
      "    (fc_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate encoder\n",
    "encoder = CNNGRUEncoder(input_dim=N_FEATURES, embedding_dim=EMBEDDING_DIM).to(DEVICE)\n",
    "encoder = torch.compile(encoder) # Compile the model after creating it\n",
    "optimizer = optim.Adam(encoder.parameters(), lr=LEARNING_RATE)\n",
    "print(\"\\nCNN-GRU Encoder Architecture:\")\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(z, temperature):\n",
    "    \"\"\"\n",
    "    Optimized implementation of NT-Xent loss using logsumexp.\n",
    "    Assumes z = torch.cat([view1, view2], dim=0)\n",
    "    where view1 and view2 have shape (B, D) and B is the batch size.\n",
    "    \"\"\"\n",
    "    n = z.shape[0] # Shape is (2*B, D)\n",
    "    if n < 2:\n",
    "        # Handle edge case where batch size is too small after drop_last\n",
    "        return torch.tensor(0.0, device=z.device, requires_grad=True)\n",
    "    batch_size = n // 2 # The original batch size B\n",
    "\n",
    "    # Calculate cosine similarity matrix (2B x 2B)\n",
    "    # Normalize features first is equivalent to cosine similarity for matrix mult\n",
    "    z_norm = F.normalize(z, p=2, dim=1)\n",
    "    sim_matrix = torch.mm(z_norm, z_norm.t()) # (2B, D) @ (D, 2B) -> (2B, 2B)\n",
    "    # Or using the function directly:\n",
    "    #sim_matrix = F.cosine_similarity(z.unsqueeze(1), z.unsqueeze(0), dim=2)\n",
    "\n",
    "\n",
    "    # Scale similarities by temperature\n",
    "    logits = sim_matrix / temperature\n",
    "\n",
    "    # --- Identify positive pairs ---\n",
    "    # Create labels identifying samples across the two views\n",
    "    labels = torch.arange(batch_size).to(z.device) # 0 to B-1\n",
    "    # Create a mask for positive pairs: (i, i+B) and (i+B, i)\n",
    "    mask_pos = torch.zeros_like(logits, dtype=torch.bool)\n",
    "    mask_pos[torch.arange(batch_size), torch.arange(batch_size) + batch_size] = True\n",
    "    mask_pos[torch.arange(batch_size) + batch_size, torch.arange(batch_size)] = True\n",
    "\n",
    "    # Extract the logits corresponding to positive pairs\n",
    "    # These are the sim(z1_k, z2_k)/T and sim(z2_k, z1_k)/T terms\n",
    "    positives = logits[mask_pos].view(n, 1) # Shape: (2B, 1)\n",
    "\n",
    "    # --- Calculate LogSumExp over negatives ---\n",
    "    # Mask out self-similarity (diagonal) for the logsumexp calculation\n",
    "    mask_self = torch.eye(n, dtype=torch.bool).to(z.device)\n",
    "    logits_masked = logits.masked_fill(mask_self, -float('inf')) # Exclude sim(i,i)\n",
    "\n",
    "    # Calculate logsumexp across all other samples (negatives + the other positive)\n",
    "    logsumexp_all = torch.logsumexp(logits_masked, dim=1, keepdim=True) # Shape: (2B, 1)\n",
    "\n",
    "    # --- Calculate final loss ---\n",
    "    # loss = log(sum(exp(negatives))) - positive_similarity\n",
    "    loss_per_sample = logsumexp_all - positives\n",
    "\n",
    "    # Average loss over all 2B samples (both views)\n",
    "    loss = loss_per_sample.mean()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Output Sequence Length: 10, Channels: 256\n",
      "Projection Head: Input=256, Hidden=256, Output=64\n",
      "\n",
      "CNN-GRU Encoder Architecture:\n",
      "OptimizedModule(\n",
      "  (_orig_mod): CNNGRUEncoder(\n",
      "    (conv1): Conv1d(1, 32, kernel_size=(9,), stride=(1,), padding=same)\n",
      "    (relu1): ReLU()\n",
      "    (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv1d(32, 64, kernel_size=(9,), stride=(1,), padding=same)\n",
      "    (relu2): ReLU()\n",
      "    (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv3): Conv1d(64, 128, kernel_size=(9,), stride=(1,), padding=same)\n",
      "    (relu3): ReLU()\n",
      "    (pool3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv4): Conv1d(128, 256, kernel_size=(9,), stride=(1,), padding=same)\n",
      "    (relu4): ReLU()\n",
      "    (gru): GRU(256, 128, num_layers=4, batch_first=True, bidirectional=True)\n",
      "    (fc_out): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Projection Head Architecture:\n",
      "OptimizedModule(\n",
      "  (_orig_mod): ProjectionHead(\n",
      "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Starting Unsupervised Training with CNN-GRU Encoder + Projection Head\n",
      "Epoch [1/10], Batch [200/795], Current Loss: 0.6271\n",
      "Epoch [1/10], Batch [400/795], Current Loss: 0.2990\n",
      "Epoch [1/10], Batch [600/795], Current Loss: 0.2481\n",
      "Epoch [1/10] Summary (Loss Type: NTXentLoss w/ Proj Head):\n",
      "\n",
      "Epoch [2/10], Batch [200/795], Current Loss: 0.2502\n",
      "Epoch [2/10], Batch [400/795], Current Loss: 0.1853\n",
      "Epoch [2/10], Batch [600/795], Current Loss: 0.1826\n",
      "Epoch [2/10] Summary (Loss Type: NTXentLoss w/ Proj Head):\n",
      "\n",
      "Epoch [3/10], Batch [200/795], Current Loss: 0.1706\n",
      "Epoch [3/10], Batch [400/795], Current Loss: 0.1869\n",
      "Epoch [3/10], Batch [600/795], Current Loss: 0.1314\n",
      "Epoch [3/10] Summary (Loss Type: NTXentLoss w/ Proj Head):\n",
      "\n",
      "Epoch [4/10], Batch [200/795], Current Loss: 0.1190\n",
      "Epoch [4/10], Batch [400/795], Current Loss: 0.1388\n",
      "Epoch [4/10], Batch [600/795], Current Loss: 0.1533\n",
      "Epoch [4/10] Summary (Loss Type: NTXentLoss w/ Proj Head):\n",
      "\n",
      "Epoch [5/10], Batch [200/795], Current Loss: 0.1275\n",
      "Epoch [5/10], Batch [400/795], Current Loss: 0.1218\n",
      "Epoch [5/10], Batch [600/795], Current Loss: 0.1256\n",
      "Epoch [5/10] Summary (Loss Type: NTXentLoss w/ Proj Head):\n",
      "\n",
      "Epoch [6/10], Batch [200/795], Current Loss: 0.1293\n",
      "Epoch [6/10], Batch [400/795], Current Loss: 0.1081\n",
      "Epoch [6/10], Batch [600/795], Current Loss: 0.1207\n",
      "Epoch [6/10] Summary (Loss Type: NTXentLoss w/ Proj Head):\n",
      "\n",
      "Epoch [7/10], Batch [200/795], Current Loss: 0.1135\n",
      "Epoch [7/10], Batch [400/795], Current Loss: 0.1116\n",
      "Epoch [7/10], Batch [600/795], Current Loss: 0.1110\n",
      "Epoch [7/10] Summary (Loss Type: NTXentLoss w/ Proj Head):\n",
      "\n",
      "Epoch [8/10], Batch [200/795], Current Loss: 0.1234\n",
      "Epoch [8/10], Batch [400/795], Current Loss: 0.1059\n",
      "Epoch [8/10], Batch [600/795], Current Loss: 0.1242\n",
      "Epoch [8/10] Summary (Loss Type: NTXentLoss w/ Proj Head):\n",
      "\n",
      "Epoch [9/10], Batch [200/795], Current Loss: 0.1015\n",
      "Epoch [9/10], Batch [400/795], Current Loss: 0.0865\n",
      "Epoch [9/10], Batch [600/795], Current Loss: 0.1048\n",
      "Epoch [9/10] Summary (Loss Type: NTXentLoss w/ Proj Head):\n",
      "\n",
      "Epoch [10/10], Batch [200/795], Current Loss: 0.1161\n",
      "Epoch [10/10], Batch [400/795], Current Loss: 0.0910\n",
      "Epoch [10/10], Batch [600/795], Current Loss: 0.1037\n",
      "Epoch [10/10] Summary (Loss Type: NTXentLoss w/ Proj Head):\n",
      "\n",
      "\n",
      "Generating final embeddings for all data (Using ENCODER Output)...\n",
      "Generated ENCODER embeddings shape: (203768, 256)\n"
     ]
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE == torch.device('cuda')))\n",
    "\n",
    "# Instantiate BOTH models\n",
    "encoder = CNNGRUEncoder(input_dim=N_FEATURES, embedding_dim=ENCODER_EMBEDDING_DIM).to(DEVICE)\n",
    "projection_head = ProjectionHead(input_dim=ENCODER_EMBEDDING_DIM, output_dim=PROJECTION_DIM).to(DEVICE)\n",
    "\n",
    "# Compile if desired (compile both or just encoder if projection is simple)\n",
    "encoder = torch.compile(encoder)\n",
    "projection_head = torch.compile(projection_head)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    list(encoder.parameters()) + list(projection_head.parameters()), # Combine parameters\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=1e-6\n",
    ")\n",
    "\n",
    "# Use the library loss function (operates on projection head output)\n",
    "criterion = NTXentLoss(temperature=TEMPERATURE, memory_bank_size=0)\n",
    "\n",
    "print(\"\\nCNN-GRU Encoder Architecture:\")\n",
    "print(encoder)\n",
    "print(\"\\nProjection Head Architecture:\")\n",
    "print(projection_head)\n",
    "\n",
    "\n",
    "# --- 6. Training Loop (Modified for Projection Head) ---\n",
    "print(\"\\nStarting Unsupervised Training with CNN-GRU Encoder + Projection Head\")\n",
    "losses = []\n",
    "gradient_check_interval = 600 # Or disable if not needed\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # --- Set BOTH models to training mode ---\n",
    "    encoder.train()\n",
    "    projection_head.train()\n",
    "    # --- Init timers and loss tracking ---\n",
    "    total_data_time = 0\n",
    "    total_forward_time =0 \n",
    "    total_backward_time=0\n",
    "    total_loss_calc_time =0\n",
    "    total_optimizer_step_time =0\n",
    "    total_grad_check_time = 0\n",
    "    epoch_loss = 0.0\n",
    "    batches_processed = 0\n",
    "    epoch_start_time = time.time()\n",
    "    # ... (initialize other timer variables) ...\n",
    "    batch_start_time = time.time()\n",
    "\n",
    "    data_iterator = enumerate(dataloader) # Assumes Augmented Dataloader\n",
    "\n",
    "    for batch_idx, (view1, view2) in data_iterator:\n",
    "        data_end_time = time.time(); total_data_time += (data_end_time - batch_start_time)\n",
    "        t0 = time.time()\n",
    "        if view1.shape[0] < 2: batch_start_time = time.time(); continue\n",
    "        view1, view2 = view1.to(DEVICE), view2.to(DEVICE)\n",
    "\n",
    "        # --- Forward Pass & Loss Calculation within Autocast ---\n",
    "        with torch.amp.autocast(device_type='cuda', dtype=torch.float16, enabled=(DEVICE == torch.device('cuda'))):\n",
    "            t1 = time.time()\n",
    "            # 1. Get ENCODER embeddings\n",
    "            z1_enc = encoder(view1)\n",
    "            z2_enc = encoder(view2)\n",
    "            # 2. Get PROJECTION HEAD embeddings\n",
    "            p1 = projection_head(z1_enc)\n",
    "            p2 = projection_head(z2_enc)\n",
    "            t2 = time.time()\n",
    "            total_forward_time += (t2 - t1)\n",
    "\n",
    "            # 3. --- Calculate Loss on PROJECTION output ---\n",
    "            loss = criterion(p1, p2) # Use p1, p2 from projection head\n",
    "            # --------------------------------------------\n",
    "            t3 = time.time()\n",
    "            total_loss_calc_time += (t3 - t2)\n",
    "\n",
    "        # --- Backpropagation, Grad Check, Optimizer Step ---\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        if torch.isnan(loss) or torch.isinf(loss):\n",
    "             print(f\"Warning: NaN/Inf loss detected at Epoch {epoch+1}, Batch {batch_idx}. Skipping.\")\n",
    "             batch_start_time = time.time(); continue\n",
    "        else:\n",
    "            # 1. Backward Pass (Scaled) - Gradients flow back through proj head AND encoder\n",
    "            t4 = time.time()\n",
    "            scaler.scale(loss).backward()\n",
    "            t5 = time.time()\n",
    "            total_backward_time += (t5 - t4)\n",
    "\n",
    "            # 2. Optional Gradient Checking (Checks grads in BOTH models now)\n",
    "            t_gc_start = time.time()\n",
    "            print_grads_this_batch = (batch_idx + 1) % gradient_check_interval == 0\n",
    "            if print_grads_this_batch:\n",
    "                 # --- (Gradient check block - unchanged, iterates encoder.named_parameters()) ---\n",
    "                 # You could modify it to iterate list(encoder.named_parameters()) + list(projection_head.named_parameters())\n",
    "                 # But checking the encoder alone is usually sufficient indicator\n",
    "                 pass # Placeholder for grad check block if used\n",
    "            t_gc_end = time.time()\n",
    "            if print_grads_this_batch: total_grad_check_time += (t_gc_end - t_gc_start)\n",
    "\n",
    "\n",
    "            # 3. Optimizer Step (Unscales gradients, updates BOTH models)\n",
    "            t6 = time.time()\n",
    "            # Optional: Clip gradients before step if needed\n",
    "            # scaler.unscale_(optimizer) # Unscale first if clipping\n",
    "            # torch.nn.utils.clip_grad_norm_(list(encoder.parameters()) + list(projection_head.parameters()), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            t7 = time.time()\n",
    "            total_optimizer_step_time += (t7 - t6)\n",
    "\n",
    "            # Accumulate loss and count batches\n",
    "            epoch_loss += loss.item()\n",
    "            batches_processed += 1\n",
    "\n",
    "\n",
    "        # Print progress periodically\n",
    "        if (batch_idx + 1) % 200 == 0:\n",
    "             if 'loss' in locals() and loss is not None :\n",
    "                 print(f\"Epoch [{epoch+1}/{EPOCHS}], Batch [{batch_idx+1}/{len(dataloader)}], Current Loss: {loss.item():.4f}\")\n",
    "\n",
    "        batch_start_time = time.time() # Reset for next data load time\n",
    "\n",
    "\n",
    "    # --- End of Epoch Summary ---\n",
    "    # ... (Print epoch summary and timings as before) ...\n",
    "    # losses.append(avg_epoch_loss)\n",
    "    avg_epoch_loss = epoch_loss / batches_processed\n",
    "    losses.append(avg_epoch_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Summary (Loss Type: NTXentLoss w/ Proj Head):\\n\")\n",
    "    # ...\n",
    "\n",
    "# --- 8. Generate Embeddings for ALL data ***USING ONLY THE ENCODER*** ---\n",
    "print(\"\\nGenerating final embeddings for all data (Using ENCODER Output)...\")\n",
    "# --- Set BOTH models to eval mode ---\n",
    "encoder.eval()\n",
    "projection_head.eval() # Set proj head to eval mode too (best practice)\n",
    "\n",
    "all_embeddings_list = []\n",
    "with torch.no_grad():\n",
    "    # Use the SIMPLE dataset (eval_dataloader)\n",
    "    for data in eval_dataloader:\n",
    "        data = data.to(DEVICE)\n",
    "        # *** GET EMBEDDINGS FROM ENCODER ONLY ***\n",
    "        embeddings = encoder(data)\n",
    "        # * DO NOT PASS THROUGH projection_head HERE *\n",
    "        all_embeddings_list.append(embeddings.cpu().numpy())\n",
    "\n",
    "# ... (Concatenate embeddings as before) ...\n",
    "if all_embeddings_list:\n",
    "     all_embeddings = np.concatenate(all_embeddings_list, axis=0)\n",
    "     all_embeddings = all_embeddings[:len(eval_dataset)]\n",
    "     print(f\"Generated ENCODER embeddings shape: {all_embeddings.shape}\") # Should be (N, ENCODER_EMBEDDING_DIM)\n",
    "else:\n",
    "     print(\"Error: No embeddings generated.\")\n",
    "     all_embeddings = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters in encoder: 1,639,424\n",
      "Total parameters in encoder: 1,639,424\n"
     ]
    }
   ],
   "source": [
    "num_trainable_params = sum(p.numel() for p in encoder.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in encoder.parameters())\n",
    "\n",
    "print(f\"Number of trainable parameters in encoder: {num_trainable_params:,}\")\n",
    "print(f\"Total parameters in encoder: {total_params:,}\")\n",
    "\n",
    "# weights = encoder.state_dict()\n",
    "# print(\"Saving model weights...\")\n",
    "# print(\"model weights are:\", weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot loss\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(1, len(losses) + 1), losses) # Adjust x-axis range based on actual epochs run\n",
    "plt.title(\"Training Loss over Epochs (CNN-GRU on Elliptic)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Contrastive Loss\")\n",
    "plt.grid(True)\n",
    "plt.savefig(\"elliptic_training_loss_cnngru.png\") # Save the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating final embeddings for all data...\n",
      "Generated embeddings shape: (203768, 256)\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating final embeddings for all data...\")\n",
    "encoder.eval()\n",
    "all_embeddings_list = []\n",
    "# Use a dataloader for all data, no shuffling, potentially larger batch\n",
    "eval_dataset = EllipticDataset(X_all_scaled)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=BATCH_SIZE * 2, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in eval_dataloader:\n",
    "        data = data.to(DEVICE)\n",
    "        embeddings = encoder(data)\n",
    "        all_embeddings_list.append(embeddings.cpu().numpy())\n",
    "\n",
    "all_embeddings = np.concatenate(all_embeddings_list, axis=0)\n",
    "print(f\"Generated embeddings shape: {all_embeddings.shape}\")\n",
    "\n",
    "# Ensure embeddings count matches original data count\n",
    "if len(all_embeddings) != len(df):\n",
    "    print(f\"Warning: Embedding count ({len(all_embeddings)}) does not match dataframe rows ({len(df)}). Check dataloading.\")\n",
    "    # Attempt to truncate if slightly off due to batching, but investigate if large difference\n",
    "    all_embeddings = all_embeddings[:len(df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # k = min_samples\n",
    "# K_FOR_EPS_GRAPH = 5 #should roughly match DBSCAN_MIN_SAMPLES\n",
    "\n",
    "# if all_embeddings is not None and len(all_embeddings) > 0:\n",
    "#     print(f\"\\n--- Calculating k-distance graph for eps estimation (k={K_FOR_EPS_GRAPH}) ---\")\n",
    "#     # Ensure data is float32\n",
    "#     if all_embeddings.dtype != np.float32:\n",
    "#          all_embeddings = all_embeddings.astype(np.float32)\n",
    "\n",
    "#     # Use NearestNeighbors to find distances\n",
    "#     # Use 'cosine' metric since embeddings are normalized\n",
    "#     print(\"Starting\")\n",
    "#     neighbors = NearestNeighbors(n_neighbors=K_FOR_EPS_GRAPH, metric='cosine', n_jobs=-1)\n",
    "#     try:\n",
    "#         neighbors_fit = neighbors.fit(all_embeddings)\n",
    "#         distances, indices = neighbors_fit.kneighbors(all_embeddings)\n",
    "\n",
    "#         # Get the distance to the k-th neighbor (k-th column, index k-1)\n",
    "#         k_distances = np.sort(distances[:, K_FOR_EPS_GRAPH-1], axis=0)\n",
    "\n",
    "#         # Plot the k-distance graph\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(k_distances)\n",
    "#         plt.title(f'{K_FOR_EPS_GRAPH}-distance Graph (Sorted)')\n",
    "#         plt.xlabel(\"Points (sorted by distance)\")\n",
    "#         plt.ylabel(f'{K_FOR_EPS_GRAPH}-th Nearest Neighbor Distance (Cosine)')\n",
    "#         plt.grid(True)\n",
    "#         print(f\"Plotting k-distance graph. Look for the 'elbow' point to estimate 'eps'.\")\n",
    "#         plt.savefig(\"dbscan_k_distance_graph.png\")\n",
    "#         plt.show()\n",
    "\n",
    "#     except MemoryError:\n",
    "#         print(\"  Error: Ran out of memory calculating nearest neighbors. Dataset might be too large for this analysis without subsampling.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"  An error occurred during k-distance calculation: {e}\")\n",
    "# else:\n",
    "#     print(\"Skipping k-distance graph calculation as embeddings are not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_anomalies_known = None # Store predictions ONLY for the known subset\n",
    "\n",
    "# # Select the embeddings corresponding to known labels\n",
    "# if all_embeddings is not None and len(known_indices) > 0:\n",
    "#     embeddings_known = all_embeddings[known_indices]\n",
    "#     if embeddings_known.dtype != np.float32:\n",
    "#         embeddings_known = embeddings_known.astype(np.float32)\n",
    "\n",
    "#     print(f\"\\n--- Applying Anomaly Detection ONLY to Labeled Subset ({len(known_indices)} points) ---\")\n",
    "#     print(f\"Embeddings shape for detection: {embeddings_known.shape}\")\n",
    "\n",
    "#     # --- Choose ONE algorithm to test here (e.g., DBSCAN) ---\n",
    "\n",
    "#     # --- Example: DBSCAN on Labeled Subset ---\n",
    "#     # NOTE: 'eps' value suitable for the full dataset might NOT be suitable for the subset!\n",
    "#     # You might need to re-run k-distance plot analysis JUST on embeddings_known\n",
    "#     DBSCAN_EPS_SUBSET = 0.05 # EXAMPLE - TUNE THIS based on k-distance plot of embeddings_known\n",
    "#     DBSCAN_MIN_SAMPLES_SUBSET = 10 # EXAMPLE - TUNE THIS\n",
    "\n",
    "#     print(f\"\\n--- Starting DBSCAN on Labeled Subset (eps={DBSCAN_EPS_SUBSET}, min_samples={DBSCAN_MIN_SAMPLES_SUBSET}) ---\")\n",
    "#     start_time = time.time()\n",
    "#     try:\n",
    "#         dbscan_subset = DBSCAN(eps=DBSCAN_EPS_SUBSET,\n",
    "#                                min_samples=DBSCAN_MIN_SAMPLES_SUBSET,\n",
    "#                                metric='cosine',\n",
    "#                                n_jobs=-1)\n",
    "#         print(\"Fitting DBSCAN model on subset...\")\n",
    "#         cluster_labels_subset = dbscan_subset.fit_predict(embeddings_known)\n",
    "#         end_time = time.time()\n",
    "#         print(f\"DBSCAN fitting on subset completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "#         noise_count_subset = np.sum(cluster_labels_subset == -1)\n",
    "#         print(f\"Number of outliers found in subset: {noise_count_subset} ({noise_count_subset / len(embeddings_known) * 100:.2f}%)\")\n",
    "\n",
    "#         # Predictions are directly for the known set\n",
    "#         predicted_anomalies_known = (cluster_labels_subset == -1).astype(int)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"\\n--- An unexpected error occurred during DBSCAN on subset: {e} ---\")\n",
    "#         predicted_anomalies_known = None\n",
    "\n",
    "#     # --- OR Example: Isolation Forest on Labeled Subset\n",
    "#     # ISO_FOREST_CONTAMINATION_SUBSET = 'auto' # Or e.g., 0.10 (illicit rate within known is ~10%)\n",
    "#     # print(f\"\\n--- Starting Isolation Forest on Labeled Subset (contamination='{ISO_FOREST_CONTAMINATION_SUBSET}') ---\")\n",
    "#     # start_time = time.time()\n",
    "#     # try:\n",
    "#     #     iso_forest_subset = IsolationForest(n_estimators=100, contamination=ISO_FOREST_CONTAMINATION_SUBSET, random_state=42, n_jobs=-1)\n",
    "#     #     preds_iso_subset = iso_forest_subset.fit_predict(embeddings_known)\n",
    "#     #     end_time = time.time()\n",
    "#     #     print(f\"IsoForest fitting on subset completed in {end_time - start_time:.2f} seconds.\")\n",
    "#     #     predicted_anomalies_known = np.where(preds_iso_subset == -1, 1, 0)\n",
    "#     #     n_anomalies_found = np.sum(predicted_anomalies_known)\n",
    "#     #     print(f\"Number of outliers found in subset: {n_anomalies_found} ({n_anomalies_found / len(embeddings_known) * 100:.2f}%)\")\n",
    "#     # except Exception as e:\n",
    "#     #     print(f\"\\n--- An unexpected error occurred during Isolation Forest on subset: {e} ---\")\n",
    "#     #     predicted_anomalies_known = None\n",
    "\n",
    "\n",
    "# else:\n",
    "#     print(\"\\nSkipping anomaly detection as embeddings or known indices are not available.\")\n",
    "\n",
    "\n",
    "# # --- 10. Evaluation (using predictions directly from the labeled subset run) ---\n",
    "# print(\"\\n--- Evaluating results from anomaly detection on labeled subset ---\")\n",
    "\n",
    "# if predicted_anomalies_known is None:\n",
    "#     print(\"Anomaly detection on subset failed or was skipped. Cannot evaluate.\")\n",
    "# elif len(y_known) != len(predicted_anomalies_known):\n",
    "#      print(f\"Error: Length mismatch between true labels ({len(y_known)}) and predictions ({len(predicted_anomalies_known)}).\")\n",
    "# elif len(y_known) == 0:\n",
    "#      print(\"No known labels available to evaluate against.\")\n",
    "# else:\n",
    "#     # True labels: y_known\n",
    "#     # Predicted: predicted_anomalies_known\n",
    "#     # --- (Standard Evaluation Metrics Calculation - Keep as before) ---\n",
    "#     accuracy = accuracy_score(y_known, predicted_anomalies_known)\n",
    "#     # ... (calculate precision, recall, f1, auroc using y_known and predicted_anomalies_known) ...\n",
    "#     # ... (print classification report) ...\n",
    "#     precision, recall, f1, _ = precision_recall_fscore_support(y_known, predicted_anomalies_known, average='binary', pos_label=1, zero_division=0)\n",
    "#     try:\n",
    "#         if len(np.unique(y_known)) > 1 and len(np.unique(predicted_anomalies_known)) > 1: auroc = roc_auc_score(y_known, predicted_anomalies_known)\n",
    "#         else: print(\"AUROC requires multiple classes in both true/pred. Skipping.\"); auroc = float('nan')\n",
    "#     except ValueError as e: print(f\"Could not calculate AUROC: {e}\"); auroc = float('nan')\n",
    "#     print(f\"\\nAccuracy (Subset): {accuracy:.4f}\")\n",
    "#     print(f\"AUROC (Subset): {auroc:.4f}\") # <<<--- CHECK THIS\n",
    "#     print(f\"Precision (Illicit): {precision:.4f}\")\n",
    "#     print(f\"Recall (Illicit): {recall:.4f}\")\n",
    "#     print(f\"F1-Score (Illicit): {f1:.4f}\")\n",
    "#     print(\"\\nClassification Report (Subset):\")\n",
    "#     print(classification_report(y_known, predicted_anomalies_known, target_names=[\"Licit (0)\", \"Illicit (1)\"], zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\n--- Evaluating on known licit/illicit transactions ---\")\n",
    "\n",
    "# if predicted_anomalies_all is None:\n",
    "#     print(\"Clustering/Anomaly detection failed or was skipped. Cannot evaluate.\")\n",
    "# elif len(known_indices) == 0:\n",
    "#      print(\"No known labels available in the dataset to evaluate against.\")\n",
    "# else:\n",
    "#     # Select predictions corresponding to known labels\n",
    "#     predicted_anomalies_known = predicted_anomalies_all[known_indices]\n",
    "#     # Make sure it handles cases where predicted_anomalies_known might be empty if known_indices was empty\n",
    "#     if len(predicted_anomalies_known) == 0:\n",
    "#          print(\"No predictions available for known labels. Cannot evaluate.\")\n",
    "#     else:\n",
    "#         accuracy = accuracy_score(y_known, predicted_anomalies_known)\n",
    "#         precision, recall, f1, _ = precision_recall_fscore_support(y_known, predicted_anomalies_known, average='binary', pos_label=1, zero_division=0) # Focus on illicit class (1)\n",
    "#         try:\n",
    "#             if len(np.unique(y_known)) > 1 and len(np.unique(predicted_anomalies_known)) > 1:\n",
    "#                  auroc = roc_auc_score(y_known, predicted_anomalies_known)\n",
    "#             else:\n",
    "#                  print(\"AUROC requires multiple classes in both true labels and predictions. Skipping AUROC calculation.\")\n",
    "#                  auroc = float('nan')\n",
    "#         except ValueError as e:\n",
    "#             print(f\"Could not calculate AUROC: {e}\")\n",
    "#             auroc = float('nan')\n",
    "#         print(f\"\\nAccuracy (known): {accuracy:.4f}\")\n",
    "#         print(f\"AUROC (known): {auroc:.4f}\")\n",
    "#         print(f\"Precision (for illicit=1): {precision:.4f}\")\n",
    "#         print(f\"Recall (for illicit=1): {recall:.4f}\")\n",
    "#         print(f\"F1-Score (for illicit=1): {f1:.4f}\")\n",
    "#         print(\"\\nClassification Report (known):\")\n",
    "#         print(classification_report(y_known, predicted_anomalies_known, target_names=[\"Licit (0)\", \"Illicit (1)\"], zero_division=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import IsolationForest # Import Isolation Forest\n",
    "# # N_CLUSTER =\n",
    "# # --- Configuration for Anomaly Detection ---\n",
    "# # Hyperparameter for Isolation Forest: Expected proportion of outliers.\n",
    "# # 'auto' lets the algorithm estimate, or set a value like 0.05, 0.10 etc.\n",
    "# # Estimating based on known illicit rate: ~4545 / 203768 = ~0.022\n",
    "# ISO_FOREST_CONTAMINATION = 0.05 # Or try 0.025, 0.05, 0.1\n",
    "\n",
    "# # --- Ensure all_embeddings is defined from previous steps ---\n",
    "# # all_embeddings = ... (Result from Section 8)\n",
    "\n",
    "# # --- 9. Anomaly Detection using Isolation Forest ---\n",
    "\n",
    "# predicted_anomalies_all = None\n",
    "# # Note: Isolation Forest doesn't produce cluster labels like KMeans/DBSCAN\n",
    "# # It produces anomaly scores or direct outlier predictions (-1/1).\n",
    "\n",
    "# if all_embeddings is not None and len(known_indices) > 0:\n",
    "#     # Ensure data is float32\n",
    "#     embeddings_known = all_embeddings[known_indices]\n",
    "#     if all_embeddings.dtype != np.float32:\n",
    "#         print(\"Converting embeddings to float32...\")\n",
    "#         embeddings_known = embeddings_known.astype(np.float32)\n",
    "\n",
    "#     print(f\"\\n--- Starting Isolation Forest Anomaly Detection ---\")\n",
    "#     print(f\"Input embeddings shape: {embeddings_known.shape}\")\n",
    "#     print(f\"Using IsolationForest with contamination='{ISO_FOREST_CONTAMINATION}'\")\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     try:\n",
    "#         # n_estimators: Number of trees in the forest\n",
    "#         # max_samples: Number of samples to draw to train each tree ('auto' is 256 or n_samples)\n",
    "#         # contamination: Expected proportion of outliers (adjust based on results)\n",
    "#         iso_forest = IsolationForest(n_estimators=100, # Default, can increase (e.g., 200)\n",
    "#                                      max_samples='auto',\n",
    "#                                      contamination=ISO_FOREST_CONTAMINATION,\n",
    "#                                      random_state=42, # For reproducibility\n",
    "#                                      n_jobs=-1)     # Use all available CPU cores\n",
    "\n",
    "#         print(\"Fitting Isolation Forest model and predicting outliers...\")\n",
    "#         # fit_predict returns 1 for inliers (normal) and -1 for outliers (anomalous)\n",
    "#         preds_iso = iso_forest.fit_predict(embeddings_known)\n",
    "\n",
    "#         end_time = time.time()\n",
    "#         print(f\"Isolation Forest fitting and prediction completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "#         # Convert predictions: -1 (outlier) -> 1 (anomaly), 1 (inlier) -> 0 (normal)\n",
    "#         predicted_anomalies_all = np.where(preds_iso == -1, 1, 0)\n",
    "\n",
    "#         n_anomalies_found = np.sum(predicted_anomalies_all)\n",
    "#         print(f\"\\nNumber of predicted anomalies (outliers by Isolation Forest): {n_anomalies_found} ({n_anomalies_found / len(embeddings_known) * 100:.2f}%)\")\n",
    "\n",
    "#         # Optional: Get anomaly scores if needed for more nuanced thresholding later\n",
    "#         # anomaly_scores = iso_forest.decision_function(all_embeddings) # Lower score means more anomalous\n",
    "#         # score_threshold = np.percentile(anomaly_scores, 5) # Example: Threshold at 5th percentile score\n",
    "#         # predicted_anomalies_all_score = (anomaly_scores < score_threshold).astype(int)\n",
    "\n",
    "\n",
    "#     except MemoryError:\n",
    "#         print(\"\\n--- ERROR: Ran out of memory during Isolation Forest fitting! ---\")\n",
    "#         print(\"Check system resources. max_samples might need adjustment if using very large datasets.\")\n",
    "#         predicted_anomalies_all = None\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"\\n--- An unexpected error occurred during Isolation Forest: {e} ---\")\n",
    "#         predicted_anomalies_all = None\n",
    "# else:\n",
    "#     print(\"\\nSkipping Isolation Forest as embeddings were not generated.\")\n",
    "\n",
    "\n",
    "# # --- 10. Evaluation (using predicted_anomalies_all from Isolation Forest if successful) ---\n",
    "# print(\"\\n--- Evaluating on known licit/illicit transactions (Isolation Forest results) ---\")\n",
    "\n",
    "# if predicted_anomalies_all is None: # Check if Isolation Forest ran successfully\n",
    "#     print(\"Anomaly detection failed or was skipped. Cannot evaluate.\")\n",
    "# elif len(known_indices) == 0:\n",
    "#      print(\"No known labels available in the dataset to evaluate against.\")\n",
    "# else:\n",
    "#     # Select predictions corresponding to known labels\n",
    "#     # predicted_anomalies_known = predicted_anomalies_all[known_indices]\n",
    "\n",
    "#     # True labels: y_known (0=licit/normal, 1=illicit/anomaly)\n",
    "#     # Predicted: predicted_anomalies_known (0=normal/inlier, 1=anomaly/outlier)\n",
    "\n",
    "#     if len(predicted_anomalies_known) == 0:\n",
    "#          print(\"No predictions available for known labels. Cannot evaluate.\")\n",
    "#     else:\n",
    "#         # --- (Standard Evaluation Metrics Calculation - Keep as before) ---\n",
    "#         accuracy = accuracy_score(y_known, predicted_anomalies_known)\n",
    "#         precision, recall, f1, _ = precision_recall_fscore_support(y_known, predicted_anomalies_known, average='binary', pos_label=1, zero_division=0)\n",
    "#         try:\n",
    "#             if len(np.unique(y_known)) > 1 and len(np.unique(predicted_anomalies_known)) > 1: auroc = roc_auc_score(y_known, predicted_anomalies_known)\n",
    "#             else: print(\"AUROC requires multiple classes in both true/pred. Skipping.\"); auroc = float('nan')\n",
    "#         except ValueError as e: print(f\"Could not calculate AUROC: {e}\"); auroc = float('nan')\n",
    "\n",
    "#         print(f\"\\nAccuracy (known): {accuracy:.4f}\")\n",
    "#         print(f\"AUROC (known): {auroc:.4f}\") # <<<--- CHECK THIS METRIC\n",
    "#         print(f\"Precision (for illicit=1): {precision:.4f}\")\n",
    "#         print(f\"Recall (for illicit=1): {recall:.4f}\")\n",
    "#         print(f\"F1-Score (for illicit=1): {f1:.4f}\")\n",
    "#         print(\"\\nClassification Report (known):\")\n",
    "#         print(classification_report(y_known, predicted_anomalies_known, target_names=[\"Licit (0)\", \"Illicit (1)\"], zero_division=0))\n",
    "\n",
    "\n",
    "# # --- Final Notes ---\n",
    "# # ... (Keep final notes as before) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Supervised Baseline Training (RandomForest) ---\n",
      "Using 46564 labeled samples for training and testing.\n",
      "Feature shape: (46564, 166)\n",
      "Train set size: 32594, Test set size: 13970\n",
      "Illicit in train: 3181, Illicit in test: 1364\n",
      "\n",
      "Training RandomForest model...\n",
      "RandomForest training completed in 5.32 seconds.\n",
      "\n",
      "Making predictions on the test set...\n",
      "\n",
      "--- Supervised RandomForest Evaluation Results ---\n",
      "Accuracy (RF): 0.9872\n",
      "AUROC (RF):    0.9944\n",
      "Precision (for illicit=1): 0.9933\n",
      "Recall (for illicit=1):    0.8746\n",
      "F1-Score (for illicit=1):  0.9302\n",
      "\n",
      "Classification Report (RF - Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Licit (0)       0.99      1.00      0.99     12606\n",
      " Illicit (1)       0.99      0.87      0.93      1364\n",
      "\n",
      "    accuracy                           0.99     13970\n",
      "   macro avg       0.99      0.94      0.96     13970\n",
      "weighted avg       0.99      0.99      0.99     13970\n",
      "\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "    feature  importance\n",
      "55      f55    0.049547\n",
      "53      f53    0.043417\n",
      "47      f47    0.040899\n",
      "14      f14    0.038653\n",
      "5        f5    0.035600\n",
      "90      f90    0.035252\n",
      "41      f41    0.033010\n",
      "132    f132    0.031320\n",
      "18      f18    0.025131\n",
      "49      f49    0.024851\n"
     ]
    }
   ],
   "source": [
    "# --- Keep necessary imports ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "# ... (other imports like os, kagglehub if needed for data loading) ...\n",
    "\n",
    "# --- Assume previous sections have run successfully ---\n",
    "# 1. Data Loading (features_df, classes_df merged into df)\n",
    "# 2. Feature Scaling (X_all_scaled created)\n",
    "# 3. Label Preparation (known_indices, y_known created)\n",
    "# --- Required variables from previous steps: ---\n",
    "# X_all_scaled: Numpy array of all scaled features (N_samples, N_features)\n",
    "# known_indices: List or array of indices corresponding to labeled data\n",
    "# y_known: Numpy array of true labels (0 or 1) for the known data\n",
    "\n",
    "# --- Supervised Baseline using RandomForest ---\n",
    "\n",
    "print(\"\\n--- Starting Supervised Baseline Training (RandomForest) ---\")\n",
    "\n",
    "if 'X_all_scaled' not in locals() or 'known_indices' not in locals() or 'y_known' not in locals():\n",
    "    print(\"Error: Prerequisite data (X_all_scaled, known_indices, y_known) not found. Ensure data loading and prep ran.\")\n",
    "    # Handle error appropriately, maybe exit()\n",
    "    exit()\n",
    "elif len(known_indices) == 0:\n",
    "    print(\"Error: No known labels available for supervised training.\")\n",
    "    exit()\n",
    "else:\n",
    "    # Select the features and labels for the known data\n",
    "    X_known_scaled = X_all_scaled[known_indices]\n",
    "    # y_known is already defined\n",
    "\n",
    "    print(f\"Using {len(y_known)} labeled samples for training and testing.\")\n",
    "    print(f\"Feature shape: {X_known_scaled.shape}\")\n",
    "\n",
    "    # Split the labeled data into training and testing sets\n",
    "    # stratify=y_known ensures similar class proportions in train/test sets\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_known_scaled,\n",
    "            y_known,\n",
    "            test_size=0.3,       # Use 30% for testing\n",
    "            random_state=42,   # For reproducibility\n",
    "            stratify=y_known   # Important for imbalanced data\n",
    "        )\n",
    "        print(f\"Train set size: {len(y_train)}, Test set size: {len(y_test)}\")\n",
    "        print(f\"Illicit in train: {np.sum(y_train==1)}, Illicit in test: {np.sum(y_test==1)}\")\n",
    "\n",
    "    except ValueError as e:\n",
    "         print(f\"Error during train_test_split (potentially too few samples of one class for stratification): {e}\")\n",
    "         exit()\n",
    "\n",
    "\n",
    "    # Initialize RandomForestClassifier\n",
    "    # Hyperparameters can be tuned, these are reasonable defaults\n",
    "    # class_weight='balanced' helps with imbalanced data\n",
    "    rf_classifier = RandomForestClassifier(\n",
    "        n_estimators=150,      # Number of trees\n",
    "        max_depth=20,          # Limit tree depth to prevent overfitting (tune this)\n",
    "        random_state=42,\n",
    "        n_jobs=-1,             # Use all CPU cores\n",
    "        class_weight='balanced' # Important for imbalanced classes\n",
    "        # min_samples_leaf=5   # Can also help prevent overfitting\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    print(\"\\nTraining RandomForest model...\")\n",
    "    start_time = time.time()\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    print(f\"RandomForest training completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    print(\"\\nMaking predictions on the test set...\")\n",
    "    y_pred_rf = rf_classifier.predict(X_test)\n",
    "    # Get probability predictions for AUROC calculation\n",
    "    # Predict probability of the positive class (illicit=1)\n",
    "    y_pred_proba_rf = rf_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Evaluate the results\n",
    "    print(\"\\n--- Supervised RandomForest Evaluation Results ---\")\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    precision_rf, recall_rf, f1_rf, _ = precision_recall_fscore_support(y_test, y_pred_rf, average='binary', pos_label=1, zero_division=0)\n",
    "\n",
    "    try:\n",
    "        # Check if both classes are present in y_test for AUROC\n",
    "        if len(np.unique(y_test)) > 1:\n",
    "             auroc_rf = roc_auc_score(y_test, y_pred_proba_rf) # Use probabilities for AUROC\n",
    "        else:\n",
    "             print(\"AUROC requires multiple classes in y_test. Skipping AUROC calculation.\")\n",
    "             auroc_rf = float('nan')\n",
    "    except ValueError as e:\n",
    "        print(f\"Could not calculate AUROC: {e}\")\n",
    "        auroc_rf = float('nan')\n",
    "\n",
    "    print(f\"Accuracy (RF): {accuracy_rf:.4f}\")\n",
    "    print(f\"AUROC (RF):    {auroc_rf:.4f}\") # <<<--- THIS IS THE KEY BASELINE METRIC\n",
    "    print(f\"Precision (for illicit=1): {precision_rf:.4f}\")\n",
    "    print(f\"Recall (for illicit=1):    {recall_rf:.4f}\")\n",
    "    print(f\"F1-Score (for illicit=1):  {f1_rf:.4f}\")\n",
    "\n",
    "    print(\"\\nClassification Report (RF - Test Set):\")\n",
    "    print(classification_report(y_test, y_pred_rf, target_names=[\"Licit (0)\", \"Illicit (1)\"], zero_division=0))\n",
    "\n",
    "    # Optional: Feature Importance\n",
    "    importances = rf_classifier.feature_importances_\n",
    "    feature_names = X_cols # From data loading section\n",
    "    importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "    importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "    print(\"\\nTop 10 Feature Importances:\")\n",
    "    print(importance_df.head(10))\n",
    "\n",
    "# --- Rest of your script (if any) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Learned Embeddings with Linear Probe (Logistic Regression) ---\n",
      "Using 46564 labeled samples for linear probe.\n",
      "Embedding shape for probe: (46564, 256)\n",
      "Linear Probe: Train size=32594, Test size=13970\n",
      "\n",
      "Training Linear Probe (Logistic Regression)...\n",
      "Linear probe training completed in 19.61 seconds.\n",
      "\n",
      "Evaluating Linear Probe on the test set...\n",
      "\n",
      "--- Linear Probe Evaluation Results ---\n",
      "Accuracy (Probe): 0.9261\n",
      "AUROC (Probe):    0.9658\n",
      "Precision (Illicit): 0.5814\n",
      "Recall (Illicit):    0.8695\n",
      "F1-Score (Illicit):  0.6968\n",
      "\n",
      "Classification Report (Probe - Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Licit (0)       0.99      0.93      0.96     12606\n",
      " Illicit (1)       0.58      0.87      0.70      1364\n",
      "\n",
      "    accuracy                           0.93     13970\n",
      "   macro avg       0.78      0.90      0.83     13970\n",
      "weighted avg       0.95      0.93      0.93     13970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression # Use Logistic Regression as probe\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, precision_recall_fscore_support\n",
    "import time\n",
    "\n",
    "print(\"\\n--- Evaluating Learned Embeddings with Linear Probe (Logistic Regression) ---\")\n",
    "\n",
    "# Ensure embeddings and known labels/indices are available from previous steps\n",
    "if 'all_embeddings' != None and 'known_indices' in locals() and 'y_known' in locals() and len(known_indices) > 0:\n",
    "\n",
    "    # Select the embeddings corresponding to known labels\n",
    "    embeddings_known = all_embeddings[known_indices]\n",
    "    # y_known holds the true labels (0 or 1)\n",
    "\n",
    "    print(f\"Using {len(y_known)} labeled samples for linear probe.\")\n",
    "    print(f\"Embedding shape for probe: {embeddings_known.shape}\")\n",
    "\n",
    "    # Split labeled embeddings into train/test for the probe\n",
    "    try:\n",
    "        X_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(\n",
    "            embeddings_known,  # Use the learned embeddings as features\n",
    "            y_known,\n",
    "            test_size=0.3,     # Use 30% for testing the probe\n",
    "            random_state=42,\n",
    "            stratify=y_known   # Stratify based on the true labels\n",
    "        )\n",
    "        print(f\"Linear Probe: Train size={len(y_train_emb)}, Test size={len(y_test_emb)}\")\n",
    "\n",
    "        # Initialize and Train the Linear Probe (Logistic Regression)\n",
    "        # Using scaled data (embeddings) often benefits logistic regression\n",
    "        # Consider adding a scaler here if embeddings aren't already well-behaved,\n",
    "        # though normalization in encoder might suffice.\n",
    "        scaler_probe = StandardScaler()\n",
    "        X_train_emb = scaler_probe.fit_transform(X_train_emb)\n",
    "        X_test_emb = scaler_probe.transform(X_test_emb)\n",
    "\n",
    "        # Use class_weight='balanced' for logistic regression too\n",
    "        linear_probe = LogisticRegression(\n",
    "            solver='liblinear', # Good solver for smaller datasets / binary classification\n",
    "            random_state=42,\n",
    "            class_weight='balanced',\n",
    "            max_iter=100\n",
    "            # C=1.0 # Regularization strength (can tune)\n",
    "            )\n",
    "\n",
    "        print(\"\\nTraining Linear Probe (Logistic Regression)...\")\n",
    "        start_time = time.time()\n",
    "        linear_probe.fit(X_train_emb, y_train_emb)\n",
    "        end_time = time.time()\n",
    "        print(f\"Linear probe training completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "        # Evaluate the probe on the test set\n",
    "        print(\"\\nEvaluating Linear Probe on the test set...\")\n",
    "        y_pred_probe = linear_probe.predict(X_test_emb)\n",
    "        # Get probabilities for AUROC\n",
    "        y_pred_proba_probe = linear_probe.predict_proba(X_test_emb)[:, 1]\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy_probe = accuracy_score(y_test_emb, y_pred_probe)\n",
    "        precision_probe, recall_probe, f1_probe, _ = precision_recall_fscore_support(y_test_emb, y_pred_probe, average='binary', pos_label=1, zero_division=0)\n",
    "        try:\n",
    "            if len(np.unique(y_test_emb)) > 1:\n",
    "                 auroc_probe = roc_auc_score(y_test_emb, y_pred_proba_probe)\n",
    "            else: auroc_probe = float('nan')\n",
    "        except ValueError as e: print(f\"Could not calculate AUROC: {e}\"); auroc_probe = float('nan')\n",
    "\n",
    "        print(\"\\n--- Linear Probe Evaluation Results ---\")\n",
    "        print(f\"Accuracy (Probe): {accuracy_probe:.4f}\")\n",
    "        print(f\"AUROC (Probe):    {auroc_probe:.4f}\") # <<<--- KEY RESULT\n",
    "        print(f\"Precision (Illicit): {precision_probe:.4f}\")\n",
    "        print(f\"Recall (Illicit):    {recall_probe:.4f}\")\n",
    "        print(f\"F1-Score (Illicit):  {f1_probe:.4f}\")\n",
    "        print(\"\\nClassification Report (Probe - Test Set):\")\n",
    "        print(classification_report(y_test_emb, y_pred_probe, target_names=[\"Licit (0)\", \"Illicit (1)\"], zero_division=0))\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error during train/test split or evaluation for linear probe: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during linear probe evaluation: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping Linear Probe evaluation as embeddings or known labels are not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Learned Embeddings with RandomForest Probe ---\n",
      "Using 46564 labeled samples for RF probe.\n",
      "Embedding shape for probe: (46564, 256)\n",
      "RF Probe: Train size=37251, Test size=9313\n",
      "\n",
      "Training RandomForest Probe...\n",
      "RF probe training completed in 35.35 seconds.\n",
      "\n",
      "Evaluating RF Probe on the test set...\n",
      "\n",
      "--- RandomForest Probe Evaluation Results ---\n",
      "Accuracy (RF Probe): 0.9741\n",
      "AUROC (RF Probe):    0.9728\n",
      "Precision (Illicit): 0.9453\n",
      "Recall (Illicit):    0.7800\n",
      "F1-Score (Illicit):  0.8547\n",
      "\n",
      "Classification Report (RF Probe - Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Licit (0)       0.98      1.00      0.99      8404\n",
      " Illicit (1)       0.95      0.78      0.85       909\n",
      "\n",
      "    accuracy                           0.97      9313\n",
      "   macro avg       0.96      0.89      0.92      9313\n",
      "weighted avg       0.97      0.97      0.97      9313\n",
      "\n",
      "\n",
      "Top 10 Embedding Dimension Importances (RF Probe):\n",
      "  Dim 129: 0.0345\n",
      "  Dim 234: 0.0268\n",
      "  Dim 252: 0.0250\n",
      "  Dim 200: 0.0245\n",
      "  Dim 116: 0.0245\n",
      "  Dim 219: 0.0226\n",
      "  Dim 93: 0.0212\n",
      "  Dim 229: 0.0188\n",
      "  Dim 68: 0.0177\n",
      "  Dim 245: 0.0167\n"
     ]
    }
   ],
   "source": [
    "# --- Keep ALL previous code sections up to generating 'all_embeddings' ---\n",
    "\n",
    "# --- Evaluate Embeddings with RandomForest Probe ---\n",
    "from sklearn.ensemble import RandomForestClassifier # Import RF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, precision_recall_fscore_support\n",
    "import time\n",
    "# ... other necessary imports\n",
    "\n",
    "print(\"\\n--- Evaluating Learned Embeddings with RandomForest Probe ---\")\n",
    "\n",
    "if 'all_embeddings' != None and 'known_indices' in locals() and 'y_known' in locals() and len(known_indices) > 0:\n",
    "\n",
    "    embeddings_known = all_embeddings[known_indices]\n",
    "    print(f\"Using {len(y_known)} labeled samples for RF probe.\")\n",
    "    print(f\"Embedding shape for probe: {embeddings_known.shape}\")\n",
    "\n",
    "    try:\n",
    "        X_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(\n",
    "            embeddings_known,\n",
    "            y_known,\n",
    "            test_size=0.2,\n",
    "            random_state=42,\n",
    "            stratify=y_known\n",
    "        )\n",
    "        print(f\"RF Probe: Train size={len(y_train_emb)}, Test size={len(y_test_emb)}\")\n",
    "\n",
    "        # --- Initialize RandomForestClassifier ---\n",
    "        rf_probe = RandomForestClassifier(\n",
    "            n_estimators=150,          # Number of trees (tune if needed)\n",
    "            max_depth=25,              # Max depth (tune if needed)\n",
    "            random_state=42,\n",
    "            n_jobs=-1,                 # Use all cores\n",
    "            class_weight='balanced',   # Good for imbalance\n",
    "            min_samples_leaf=5         # Helps prevent overfitting (tune)\n",
    "            # oob_score=True           # Can use Out-of-Bag score for validation\n",
    "        )\n",
    "        # --------------------------------------\n",
    "\n",
    "        print(\"\\nTraining RandomForest Probe...\")\n",
    "        start_time = time.time()\n",
    "        rf_probe.fit(X_train_emb, y_train_emb)\n",
    "        end_time = time.time()\n",
    "        print(f\"RF probe training completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "        # Evaluate the probe on the test set\n",
    "        print(\"\\nEvaluating RF Probe on the test set...\")\n",
    "        y_pred_probe_rf = rf_probe.predict(X_test_emb)\n",
    "        y_pred_proba_probe_rf = rf_probe.predict_proba(X_test_emb)[:, 1] # Probabilities for class 1\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy_probe_rf = accuracy_score(y_test_emb, y_pred_probe_rf)\n",
    "        precision_probe_rf, recall_probe_rf, f1_probe_rf, _ = precision_recall_fscore_support(y_test_emb, y_pred_probe_rf, average='binary', pos_label=1, zero_division=0)\n",
    "        try:\n",
    "            if len(np.unique(y_test_emb)) > 1: auroc_probe_rf = roc_auc_score(y_test_emb, y_pred_proba_probe_rf)\n",
    "            else: auroc_probe_rf = float('nan')\n",
    "        except ValueError as e: print(f\"Could not calculate AUROC: {e}\"); auroc_probe_rf = float('nan')\n",
    "\n",
    "        print(\"\\n--- RandomForest Probe Evaluation Results ---\")\n",
    "        print(f\"Accuracy (RF Probe): {accuracy_probe_rf:.4f}\")\n",
    "        print(f\"AUROC (RF Probe):    {auroc_probe_rf:.4f}\") # <<<--- KEY RESULT\n",
    "        print(f\"Precision (Illicit): {precision_probe_rf:.4f}\")\n",
    "        print(f\"Recall (Illicit):    {recall_probe_rf:.4f}\")\n",
    "        print(f\"F1-Score (Illicit):  {f1_probe_rf:.4f}\")\n",
    "        print(\"\\nClassification Report (RF Probe - Test Set):\")\n",
    "        print(classification_report(y_test_emb, y_pred_probe_rf, target_names=[\"Licit (0)\", \"Illicit (1)\"], zero_division=0))\n",
    "\n",
    "        # Optional: Feature Importance (Importance of embedding dimensions)\n",
    "        importances_rf = rf_probe.feature_importances_\n",
    "        emb_indices = np.argsort(importances_rf)[::-1] # Sort descending\n",
    "        print(\"\\nTop 10 Embedding Dimension Importances (RF Probe):\")\n",
    "        for i in range(10):\n",
    "            print(f\"  Dim {emb_indices[i]}: {importances_rf[emb_indices[i]]:.4f}\")\n",
    "\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error during train/test split or evaluation for RF probe: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during RF probe evaluation: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping RF Probe evaluation as embeddings or known labels are not available.\")\n",
    "\n",
    "# --- (Rest of script) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
